**Architecture:** Modern Llama
**Shape:** The "Dense Spiral"
**Concept:** Complex Reasoning

A 1.1 Billion parameter giant. Its dense, rotary-embedded structure allows for deep, multi-step logical reasoning.

### History
Part of the **2023** "Small Language Model" revolution. It proved that training a smaller model on significantly more tokens (3 Trillion) could rival much larger legacy models.