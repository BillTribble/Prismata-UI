**Architecture:** Multimodal (ViT + Transformer)\n**Shape:** The "Twin Spires"\n**Concept:** Semantic Bridging\n\nTwo distinct minds in one body: a Vision Transformer (ViT) and a Text Transformer. They project data into a shared embedding space, allowing the model to "see" concepts in images.\n\n### History\nReleased by OpenAI in **2021**. CLIP enabled the explosion of AI Art generation (like DALL-E and Midjourney) by providing a way to mathematically measure how well an image matches a text prompt.
